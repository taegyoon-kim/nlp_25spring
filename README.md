# HSS 510: NLP for Humanities and Social Sciences

**Spring 2025**  
**Tue 10:00–1:00pm**  
**N4, School of Digital Humanities and Computational Social Sciences**

## Instructor
- **Name:** Taegyoon Kim, Ph.D. in Political Science and Social Data Analytics
- **Email:** [taegyoon@kaist.ac.kr](mailto:taegyoon@kaist.ac.kr)
- **Office hours:** Wed 10:00am–12:00pm & By appointment, N4 1308
- **Webpage:** [https://taegyoon-kim.github.io](https://taegyoon-kim.github.io)

## Course Overview
This course introduces students to the fundamental concepts and techniques of Natural Language Processing (NLP), emphasizing the development of critical insights for its application in humanities and social sciences research. The course will blend theoretical understanding with practical, hands-on experience. Students will develop not only a mathematical/statistical intuition for key NLP approaches but also learn how to effectively implement these approaches in their own research. Each class will start with a lecture by the instructor, complemented by guided coding. The latter portion of the class will feature two activities. Students will first engage in a review of applied research. This will be followed by a student's hands-on methods tutorial specifically tailored to the topic of the week. While prior experience in NLP is not required, students should possess basic programming skills in Python (knowledge of both Python and R preferred), along with some familiarity with quantitative analysis. By the end of this course, students will gain a comprehensive understanding of NLP's potential in humanities and social sciences, mastering techniques to apply and refine NLP for their research.

## Prerequisites
Basic programming skills in Python and familiarity with quantitative analysis are required

## Text books
Students will engage with articles, supplemented by the following textbooks (sections provided weekly):

- **[GRS]** Grimmer, J., Roberts, M.E., & Stewart, B.M. (2022). *Text as Data: A New Framework for Machine Learning and the Social Sciences*. [Link](https://product.kyobobook.co.kr/detail/S000002751294)

- **[JM]** Jurafsky, D. & Martin, J.H. *Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition*. [Link](https://web.stanford.edu/~jurafsky/slp3/)

- **[AG]** Alammar, J. & Grootendorst, M. (2024). *Hands-On Large Language Models: Language Understanding and Generation*. [Link](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961)

## Major Tasks

- **Attendance (10%)**: Attend all lectures unless excused by the instructor. Two points deducted per absence; late arrivals beyond 20 minutes count as absences.

- **Application Review Discussion (20%)**: Students (in groups) will present and lead a discussion on an applied NLP article.

- **Methods Tutorial (20%)**: Students (in groups) will present a hands-on methods tutorial using their own (or publicly available) data.

- **Exercises (10%)**: Take-home exercises will be assigned to strengthen understanding of concepts and enhance coding skills.
    
- **Research Paper (40%)**: Students will write a research paper (2,000–4,000 words).
  
## Application Review Discussion Details
- Present a review of an applied NLP article, including:
  1) Research objectives/questions.
  2) Text data used and collection methods.
  3) NLP methods applied.
  4) Pros/cons of the methods.
  5) Suggestions for improvement.
- The presentation should last up to 15 minutes and will be followed by a 10-minute open discussion.
    - Non-presentings students are required to acively engage in the open disucssion.
- Upload your presentation slides to the **applied_discussion_slides** folder [here](https://drive.google.com/drive/folders/1w3xBhbPXvhQsElDQISanHKIz9eRAJSiP?usp=share_link)

## Methods Tutorial Details
- Present and demonstrate the implementation of NLP techniques using real data (preferably your own data).
- Walk the class through the script, explaining each step and ensuring everyone can follow.
- Upload yuor tutorial materials (scripts, datasets) prior to the presentation to the **tutorial materials** folder [here](https://drive.google.com/drive/folders/1w3xBhbPXvhQsElDQISanHKIz9eRAJSiP?usp=share_link)

## Research Paper Details
- The paper should follow a format that includes a title, abstract, main text, references, and appendices or supplementary materials.
- The expected length is 2,000–4,000 words, although longer papers are also accepted.
- Papers and replication materials must be suitable for submission to a peer-reviewed journal.
- The one-page proposals, which are ungraded, are due on April 18, and the final papers are due on June 20
- Upload your one-page proosal to the **one_page_proposals** folder [here](https://drive.google.com/drive/folders/1w3xBhbPXvhQsElDQISanHKIz9eRAJSiP?usp=share_link)
- Upload your final papers to the **final_papers** folder [here](https://drive.google.com/drive/folders/1w3xBhbPXvhQsElDQISanHKIz9eRAJSiP?usp=share_link)
  
## Weekly Schedule

### Week 1 (Feb 25): Course Overview
  - Objectives, class components, weekly themes  
  - Install Python before the next class  

### Week 2 (Mar 4): Selecting and Cleaning Texts
- Required reading:
  - [GRS] Chp. 3 (Sections 3.1 and 3.2) and Chp. 4  
  - [JM] Chp. 2 (Sections 2.1 and 2.2)  

### Week 3 (Mar 11): Representing and Comparing Texts  
- Required reading:
  - [GRS] Chp. 5 and Chp. 7  
  - Denny & Spirling (2018)  
- Optional reading: [GRS] Chp. 3 (Sections 3.3 and 3.4)  

### Week 4 (Mar 18): Supervised Learning Methods I  
- Required reading:
  - [GRS] Chps. 17–20  
  - [JM] Chp. 5  
  - Siegel et al. (2021)  

### Week 5 (Mar 25): Supervised Learning Methods II  
- Required reading:
  - [JM] Chp. 7 (Sections 7.1–7.4, 7.6)  
  - Bestvater & Monroe (2023)  

### Week 6 (Apr 1): Embeddings  
- Required reading:
  - [GRS] Chp. 8  
  - [JM] Chp. 6  
  - Kozlowski et al. (2019)  

### Week 7 (Apr 8): Topic Models
- Required reading:
  - [GRS] Chp. 13  
  - Blei (2012)  

### Week 8 (Apr 15): Mid-term Break
- No class

### Week 9 (Apr 22): One-on-One Meetings 
- Schedule individual sessions with the instructor  

### Week 10 (Apr 29): NLP with Korean
- Guest lecture by TBD

### Week 11 (May 6): Children's Day
- No class

### Week 12 (May 13): Neural NLP I  
- Required reading:
  - Smith (2019)  
  - Visualizing Neural Machine Translation [[link]](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)  
  - The Illustrated Transformer [[link]](https://jalammar.github.io/illustrated-transformer/)  
  - BERTopic GitHub Page [[link]](https://maartengr.github.io/BERTopic/index.html)  

### Week 13 (May 20): Neural NLP II  
- Required reading:
  - Illustrated BERT, ELMo, and Co. [[link]](https://jalammar.github.io/illustrated-bert/)  
  - [JM] Chp. 11  
  - Rogers et al. (2021)  

### Week 14 (May 27): Large Language Models I  
  - Required reading:
    - [AG] Chapters TBD  
    - Additional readings TBD  

### Week 15 (Jun 3): Large Language Models II  
- Required reading:
  - [AG] Chapters TBD  
  - Additional readings TBD  

### Week 16 (Jun 10): Writing Research Paper
- No class


## Policies
- **Instruction Mode:** In-person, with potential changes announced in advance.
- **Email Policy:** Emails are typically answered within two business days.
- **Late Submissions:** 10% penalty per day late.
- **Syllabus Changes:** The syllabus may be adjusted to accommodate students' progress and needs.

## Academic Integrity
As students at KAIST, you are entrusted with upholding the utmost standards of academic integrity. Academic honesty is paramount, and any form of misconduct is strictly prohibited. In the event of suspected misconduct, our course adheres to the established policy of KAIST. 

## Grading Scale
| Grade | Lower | Upper |
|-------|-------|-------|
| A+    | 90    | 101   |
| A₀    | 87    | 90    |
| A-    | 84    | 87    |
| B+    | 81    | 84    |
| B₀    | 78    | 81    |
| B-    | 75    | 78    |
| C+    | 72    | 75    |
| C₀    | 69    | 72    |
| C-    | 66    | 69    |
| D+    | 63    | 66    |
| D₀    | 60    | 63    |
| F     | 0     | 60    |
